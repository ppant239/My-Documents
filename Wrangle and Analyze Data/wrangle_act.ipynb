{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we will be gathering, assessing, cleaning, analyzing, and visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 16:23:56 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892420643...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Phineas</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 00:17:27 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Tilly. She's just checking pup on you....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892177421...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Tilly</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "0  892420643555336193                    NaN                  NaN   \n",
       "1  892177421306343426                    NaN                  NaN   \n",
       "\n",
       "                   timestamp  \\\n",
       "0  2017-08-01 16:23:56 +0000   \n",
       "1  2017-08-01 00:17:27 +0000   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text  retweeted_status_id  \\\n",
       "0  This is Phineas. He's a mystical boy. Only eve...                  NaN   \n",
       "1  This is Tilly. She's just checking pup on you....                  NaN   \n",
       "\n",
       "   retweeted_status_user_id retweeted_status_timestamp  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "\n",
       "                                       expanded_urls  rating_numerator  \\\n",
       "0  https://twitter.com/dog_rates/status/892420643...                13   \n",
       "1  https://twitter.com/dog_rates/status/892177421...                13   \n",
       "\n",
       "   rating_denominator     name doggo floofer pupper puppo  \n",
       "0                  10  Phineas  None    None   None  None  \n",
       "1                  10    Tilly  None    None   None  None  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the csv file into a DataFrame\n",
    "archive_df = pd.read_csv('twitter-archive-enhanced.csv')\n",
    "archive_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>p2</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>p3</th>\n",
       "      <th>p3_conf</th>\n",
       "      <th>p3_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>666020888022790149</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Welsh_springer_spaniel</td>\n",
       "      <td>0.465074</td>\n",
       "      <td>True</td>\n",
       "      <td>collie</td>\n",
       "      <td>0.156665</td>\n",
       "      <td>True</td>\n",
       "      <td>Shetland_sheepdog</td>\n",
       "      <td>0.061428</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>666029285002620928</td>\n",
       "      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.506826</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.074192</td>\n",
       "      <td>True</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.072010</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>666033412701032449</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>German_shepherd</td>\n",
       "      <td>0.596461</td>\n",
       "      <td>True</td>\n",
       "      <td>malinois</td>\n",
       "      <td>0.138584</td>\n",
       "      <td>True</td>\n",
       "      <td>bloodhound</td>\n",
       "      <td>0.116197</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>666044226329800704</td>\n",
       "      <td>https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.408143</td>\n",
       "      <td>True</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.360687</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.222752</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>666049248165822465</td>\n",
       "      <td>https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.560311</td>\n",
       "      <td>True</td>\n",
       "      <td>Rottweiler</td>\n",
       "      <td>0.243682</td>\n",
       "      <td>True</td>\n",
       "      <td>Doberman</td>\n",
       "      <td>0.154629</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                          jpg_url  \\\n",
       "0  666020888022790149  https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg   \n",
       "1  666029285002620928  https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg   \n",
       "2  666033412701032449  https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg   \n",
       "3  666044226329800704  https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg   \n",
       "4  666049248165822465  https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg   \n",
       "\n",
       "   img_num                      p1   p1_conf  p1_dog                  p2  \\\n",
       "0        1  Welsh_springer_spaniel  0.465074    True              collie   \n",
       "1        1                 redbone  0.506826    True  miniature_pinscher   \n",
       "2        1         German_shepherd  0.596461    True            malinois   \n",
       "3        1     Rhodesian_ridgeback  0.408143    True             redbone   \n",
       "4        1      miniature_pinscher  0.560311    True          Rottweiler   \n",
       "\n",
       "    p2_conf  p2_dog                   p3   p3_conf  p3_dog  \n",
       "0  0.156665    True    Shetland_sheepdog  0.061428    True  \n",
       "1  0.074192    True  Rhodesian_ridgeback  0.072010    True  \n",
       "2  0.138584    True           bloodhound  0.116197    True  \n",
       "3  0.360687    True   miniature_pinscher  0.222752    True  \n",
       "4  0.243682    True             Doberman  0.154629    True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "img_req = requests.get(url, allow_redirects=True)\n",
    "\n",
    "open('image_predictions.tsv', 'wb').write(img_req.content)\n",
    "image_df = pd.read_csv('image_predictions.tsv', sep = '\\t')\n",
    "image_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pp/Documents/Udacity/Wrangle and Analyze Data\n",
      "['wrangle_act.ipynb', 'twitter-archive-enhanced.csv', '.DS_Store', 'twitter-archive-enhanced-2.csv', 'image_predictions.tsv', 'twitter_api.ipynb', 'image-predictions-3.tsv', 'tweet_json_1.txt', '.ipynb_checkpoints', 'image-predictions.tsv', 'tweet_json.txt', 'tweet-json.zip']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "arr = os.listdir('.')\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fbe18c0d98c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtweet_json\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mtweet_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'retweeted_status'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Original'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mretweet_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'I am an original tweet'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m         raise ValueError(\n\u001b[0;32m-> 1479\u001b[0;31m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1480\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "# Loading the Twitter data without creating Twitter account\n",
    "tweet_json_df = pd.read_json('tweet_json_1.txt',lines=True)\n",
    "\n",
    "tweet_json_df[\"retweeted_status\"].fillna(\"Original\", inplace = True) \n",
    "\n",
    "\n",
    "#filtered_df = tw_counts_df[tw_counts_df['retweeted_status'].notnull()]\n",
    "#filtered_df.info()\n",
    "columns = ['tweet_id','favorite_count','retweet_count','retweeted','retweeted_status']#,'retweet_status']\n",
    "#df1 = pd.DataFrame(filtered_df, columns=columns)\n",
    "#df1.head()\n",
    "\n",
    "tweet_json = pd.DataFrame(tweet_json_df, columns=columns)\n",
    "tweet_json.head()\n",
    "\n",
    "if tweet_json['retweeted_status'] == 'Original':\n",
    "    retweet_status = 'I am an original tweet'\n",
    "else:\n",
    "    retweet_status = 'I am not an original tweet'\n",
    "\n",
    "\n",
    "#print(filtered_df['retweeted_status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'retweeted_status'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2ce6a4c86270>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#retweeted_status = tweet_json['retweeted_status']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mfavorite_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'favorite_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mretweeted_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"retweeted_status\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Original\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \"\"\"\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtweet_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'retweeted_status'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Original\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'retweeted_status'"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "with open('tweet_json.txt','r') as f:\n",
    "    for line in f.readlines():\n",
    "        tweet_json = json.loads(line)\n",
    "        tweet_id = tweet_json['id']\n",
    "        favorite_count = tweet_json['favorite_count']\n",
    "        retweet_count = tweet_json['retweet_count']\n",
    "        retweeted = tweet_json['retweeted']\n",
    "        #retweeted_status = tweet_json['retweeted_status']\n",
    "        favorite_count = tweet_json['favorite_count']\n",
    "        retweeted_status = tweet_json[\"retweeted_status\"].fillna(\"Original\", inplace = True)\n",
    "        \"\"\"\n",
    "        if tweet_json['retweeted_status'] == \"Original\":\n",
    "            retweet_status = 'I am original tweet'\n",
    "        else:\n",
    "            retweet_status = 'I am not an original tweet'  \n",
    "        \"\"\"\n",
    "            \n",
    "        l.append({'tweet_id': tweet_id,\n",
    "                        'favorite_count':favorite_count,\n",
    "                        'retweet_count':retweet_count,\n",
    "                        'retweeted':retweeted,\n",
    "                        'retweeted_status':retweeted_status\n",
    "                       })\n",
    "tweet_df = pd.DataFrame(l,columns = ['tweet_id','favorite_count','retweet_count','retweeted','retweeted_status'])\n",
    "#tweet_df['retweeted_status'].value_counts()\n",
    "tweet_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing data\n",
    "### Goal: Identify quality and tidiness issues.<br/> Detect and document at least eight (8) quality issues and two (2) tidiness issues in your wrangle_act.ipynb Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df.info()\n",
    "archive_df.head()\n",
    "\n",
    "# Issue 1: Missing data for columns in archive_df - in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id,retweeted_status_user_id, retweeted_status_timestamp \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.info()\n",
    "image_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.info()\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for duplicates\n",
    "\n",
    "#sum(image_df.jpg_url.duplicated())\n",
    "print('Duplicates in archive df: ',archive_df.duplicated().sum())\n",
    "print('Duplicates in image df: ',image_df.duplicated().sum())\n",
    "print('Duplicates in tweet df: ',tweet_df.duplicated().sum())\n",
    "\n",
    "print('Duplicates in archive df for tweet id: ',archive_df['tweet_id'].duplicated().sum())\n",
    "print('Duplicates in image df for tweet id: ',image_df['tweet_id'].duplicated().sum())\n",
    "print('Duplicates in tweet df for tweet id: ',tweet_df['tweet_id'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NULL values\n",
    "archive_df.isnull().sum()\n",
    "#same as Issue # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep dive into each of the data sets\n",
    "#archive_df.info()\n",
    "archive_df['name'].value_counts()\n",
    "#Issue 2: There are names such as 'None', 'a', 'such','O','a', 'actually', 'all', 'an', \n",
    "#       'the', 'this', 'unacceptable', 'very','my', 'not', 'officially', 'by', 'getting',\n",
    "#      'his'\n",
    "np.sort(archive_df['name'].unique())\n",
    "#archive_df.query(\"name == 'an'\").loc[:,['text','name']]\n",
    "#Issue # 3: Most of the names starts with Caps \n",
    "#while there are few at the end starting with small letter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_df.info()\n",
    "archive_df.head()\n",
    "print(np.sort(archive_df['doggo'].unique()))\n",
    "print(np.sort(archive_df['floofer'].unique()))\n",
    "print(np.sort(archive_df['pupper'].unique()))\n",
    "print(np.sort(archive_df['puppo'].unique()))\n",
    "\n",
    "print(archive_df['doggo'].value_counts())\n",
    "print(archive_df['floofer'].value_counts())\n",
    "print(archive_df['pupper'].value_counts())\n",
    "print(archive_df['puppo'].value_counts())\n",
    "\n",
    "#find records with none of the columns populated with correct value\n",
    "archive_df.loc[(archive_df['doggo']== 'None') & (archive_df['floofer']== 'None') & (archive_df['pupper']== 'None') & (archive_df['puppo']== 'None')]\n",
    "\n",
    "\n",
    "#Issue # 3: The four columns, doggo, floofer, pupper and puppo has all the values\n",
    "#populated as None for 1976/2356 records, so there is no dog \"stage\" (i.e. doggo, floofer, pupper, and puppo) information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze rating numerator and denominator\n",
    "print(np.sort(archive_df['rating_numerator'].unique()))\n",
    "print(archive_df['rating_numerator'].value_counts())\n",
    "\n",
    "\n",
    "#Issue 4: Rating numerator is 1776 for one record and 0 for two records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze rating numerator and denominator\n",
    "print(np.sort(archive_df['rating_denominator'].unique()))\n",
    "print(archive_df['rating_denominator'].value_counts())\n",
    "\n",
    "#Issue 4: Rating denominator is expected to be 10 but there are other value too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You only want original ratings (no retweets) that have images. \n",
    "#Though there are 5000+ tweets in the dataset, not all are dog ratings and some are retweets.\n",
    "\n",
    "#analyze retweet data\n",
    "print(\"Total retweets:\",archive_df.shape)\n",
    "#print(\"Not a Retweet\",archive_df['retweeted_status_id'].isnull().sum())\n",
    "count_null = archive_df['retweeted_status_id'].isnull().sum()\n",
    "print ('Original Tweets (retweet ID as NULL): ' + str(count_null))\n",
    "print(\"Total retweets:\",archive_df.shape[0] - count_null)\n",
    "\n",
    "#Issue 5: We are not intrested in retweets and there are 181 retweets in the archive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets analyze images data\n",
    "image_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.isnull().sum()\n",
    "# No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df['tweet_id'].duplicated().any()\n",
    "# No duplicates for tweet id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------p1_dog-----\\n',image_df['p1_dog'].value_counts())\n",
    "print('------p2_dog-----\\n',image_df['p2_dog'].value_counts())\n",
    "print('------p3_dog-----\\n',image_df['p3_dog'].value_counts())\n",
    "\n",
    "#print(image_df.loc[(image_df['p1_dog']== False) & (image_df['p2_dog']== False) & (image_df['p3_dog']== False)])\n",
    "\n",
    "not_a_dog = image_df.loc[(image_df['p1_dog']== False) & (image_df['p2_dog']== False) & (image_df['p3_dog']== False)] \n",
    "print('------not_a_dog----\\n',not_a_dog['tweet_id'].value_counts())\n",
    "\n",
    "# Issue 6: There are 324 records for which all three algorithm predeictions is other than \n",
    "# the dog breed\n",
    "# We could saave time by removing these records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.head()\n",
    "#print('------image num-----\\n',image_df['img_num'].value_counts())\n",
    "\n",
    "# Issue 7: The dog breed names populated in the p1, p2 and p2 are not consistent\n",
    "#few are starting with CAPS while others are with lowercase\n",
    "\n",
    "# Issue 8: There are multiple dog breeds in one column with underscore as delimiter\n",
    "# we may want to consider one for analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates in the url\n",
    "image_df['jpg_url'].duplicated().any()\n",
    "\n",
    "print('Duplicates URLs: ',image_df['jpg_url'].duplicated().sum())\n",
    "\n",
    "# Issue 9: There are 66 duplciate URLS, which means same pic has been uploaded which\n",
    "# will not provide additional information and we may want to delete the duplicate pics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the lst file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.head(11)\n",
    "tweet_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.isnull().sum()\n",
    "# no NULL values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['tweet_id'].duplicated().any()\n",
    "# No duplicates for tweet id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.retweeted.value_counts()\n",
    "# All the values for 'retweeted' column is False, hence we may want to use retweeted_status\n",
    "# for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
